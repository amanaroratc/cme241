{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.util import *\n",
    "from lib.policy import *\n",
    "from lib.mdp import *\n",
    "from lib.mrp import *\n",
    "from lib.env import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\varepsilon$-Greedy Policy Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Theorem\n",
    "For any $\\varepsilon$-greedy policy $\\pi$, the $\\varepsilon$-greedy policy $\\pi'$ with respect to $q_\\pi$ is an improvement, $v_{\\pi'}(s) \\geq v_{\\pi}(s)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Proof\n",
    "\\begin{align*}\n",
    "v_{\\pi'}(s) &= \\sum_{a \\in A} \\pi'(a\\mid s)q_{\\pi}(s, a) \\\\\n",
    "&= \\frac{\\varepsilon}{m} \\sum_{a \\in A} q_{\\pi}(s, a) + (1-\\varepsilon)\\max_{a \\in A}q_{\\pi}(s, a) \\\\\n",
    "&\\geq  \\frac{\\varepsilon}{m}\\sum_{a \\in A} q_{\\pi}(s, a) + (1-\\varepsilon)\\mathbb{E}_{\\sim (\\pi - \\varepsilon/m)/(1-\\varepsilon)}[q_{\\pi}(s, a)] \\\\\n",
    "&= \\frac{\\varepsilon}{m}\\sum_{a \\in A} q_{\\pi}(s, a) + (1-\\varepsilon)\\sum_{a \\in A} \\frac{\\pi(a\\mid s)-\\varepsilon/m}{1-\\varepsilon}q_{\\pi}(s, a) \\\\\n",
    "&= \\sum_{a \\in A} \\pi(a\\mid s)q_{\\pi}(s, a) \\\\\n",
    "&= v_\\pi(s)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLIE (Greedy in the Limit with Infinite Exploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All state-action pairs are explored infinitely many times,\n",
    "$$ lim_{k\\rightarrow \\infty} N_k (s, a) = \\infty $$\n",
    "The policy converges on a greedy policy,\n",
    "$$ lim_{k\\rightarrow \\infty} \\pi_k (a\\mid s) = \\mathbb{1}[a = \\text{argmax}_{a' \\in A} Q_k (s, a'))] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.sarsa import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.q_learning import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "n_episodes = 50\n",
    "gamma = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = generate_stochastic_matrix(n)\n",
    "R = generate_reward_vector(n)\n",
    "mrp = MRP(P, R, gamma)\n",
    "mdp = MDP(gamma, [mrp]*n)\n",
    "Q = generate_stochastic_matrix(n)\n",
    "policy = Policy(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Env(mdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {(2, 0): 5.255554505229622,\n",
       "             (4, 1): 5.371815661292635,\n",
       "             (4, 2): 5.37245104530005,\n",
       "             (1, 3): 5.359127460985131,\n",
       "             (1, 2): 5.3080752777947495,\n",
       "             (0, 2): 5.370819571397378,\n",
       "             (0, 4): 5.3749971396650125,\n",
       "             (3, 4): 5.357324721816808,\n",
       "             (3, 2): 5.30810839103836,\n",
       "             (3, 1): 5.341268632384486,\n",
       "             (2, 2): 5.2856603300225995,\n",
       "             (1, 1): 5.329937524176479,\n",
       "             (0, 0): 5.373468549409457,\n",
       "             (2, 1): 5.267547396111219,\n",
       "             (4, 4): 5.320989495041044,\n",
       "             (1, 4): 5.296409181647264,\n",
       "             (3, 0): 5.358047848344734,\n",
       "             (2, 4): 5.273695777669573,\n",
       "             (0, 3): 5.365308775747046,\n",
       "             (4, 3): 5.298296622038616,\n",
       "             (3, 3): 5.361022507904353,\n",
       "             (2, 3): 5.184043081767655,\n",
       "             (0, 1): 5.379814922916327,\n",
       "             (1, 0): 5.366330691058405,\n",
       "             (4, 0): 5.377766608910878})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarsa(env, n_episodes, policy, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {(0, 2): 5.577850141381746,\n",
       "             (3, 0): 5.557718054335265,\n",
       "             (3, 1): 5.559811932532149,\n",
       "             (3, 2): 5.598494113753515,\n",
       "             (3, 3): 5.572985907082252,\n",
       "             (3, 4): 5.565204071126154,\n",
       "             (4, 0): 5.577245206536512,\n",
       "             (4, 1): 5.5681106283452415,\n",
       "             (4, 2): 5.599632076419162,\n",
       "             (4, 3): 5.562098817110833,\n",
       "             (4, 4): 5.584706708824207,\n",
       "             (1, 0): 5.517823104865967,\n",
       "             (1, 1): 5.543793056437715,\n",
       "             (1, 2): 5.5734643140125355,\n",
       "             (1, 3): 5.508933520154736,\n",
       "             (1, 4): 5.53873081185546,\n",
       "             (2, 0): 5.46376875634113,\n",
       "             (2, 1): 5.525759286084648,\n",
       "             (2, 2): 5.5161474274179625,\n",
       "             (2, 3): 5.221219776255717,\n",
       "             (2, 4): 5.469836844432971,\n",
       "             (0, 0): 5.581410916734324,\n",
       "             (0, 1): 5.605840357763873,\n",
       "             (0, 3): 5.596331300564556,\n",
       "             (0, 4): 5.594725175236307})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qLearning(env, n_episodes, policy, gamma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
